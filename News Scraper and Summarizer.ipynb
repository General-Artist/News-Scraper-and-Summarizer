{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import tkinter as tk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textSplitter(text):  \n",
    "    index = 0\n",
    "    count = 0\n",
    "    for i in text:\n",
    "        if i == \" \":\n",
    "            count += 1\n",
    "            if count % 5 == 0:\n",
    "                text = text[:index] + \"\\n\" + text[index+1:]\n",
    "        index += 1\n",
    "    return text\n",
    "\n",
    "def contentSummarizer(text):\n",
    "    stopWords = set(stopwords.words(\"english\"))\n",
    "    words = word_tokenize(text)\n",
    "    freqTable = {}\n",
    "\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        if word in stopWords:\n",
    "            continue\n",
    "        if word in freqTable:\n",
    "            freqTable[word] += 1\n",
    "        else: \n",
    "            freqTable[word] = 1\n",
    "\n",
    "    sentences = sent_tokenize(text)\n",
    "    sentenceValue = {}\n",
    "\n",
    "    for sentence in sentences: \n",
    "        for word, freq in freqTable.items(): \n",
    "            if word in sentence.lower(): \n",
    "                if sentence in sentenceValue: \n",
    "                    sentenceValue[sentence] += freq \n",
    "                else: \n",
    "                    sentenceValue[sentence] = freq \n",
    "\n",
    "    sumValues = 0\n",
    "    for sentence in sentenceValue:\n",
    "        sumValues += sentenceValue[sentence]\n",
    "    average = int(sumValues/len(sentenceValue))\n",
    "\n",
    "    summary = \"\" \n",
    "    for sentence in sentences:\n",
    "        if (sentence in sentenceValue) and (sentenceValue[sentence] > 1.1 * average):\n",
    "            summary += sentence + \" \"   \n",
    "    \n",
    "    print(textSplitter(summary))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "External Affairs Minister S Jaishankar\n",
      "emphasized that India maintains a\n",
      "robust stance on terrorism, stating,\n",
      "\"we are big victims of\n",
      "terrorism.\" We will have no\n",
      "credibility if we say that\n",
      "when terrorism impacts us, it's\n",
      "very serious; when it happens\n",
      "to somebody else, it's not\n",
      "serious. \n"
     ]
    }
   ],
   "source": [
    "userInput = input(\"Enter your content: \")\n",
    "contentSummarizer(userInput)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
